---
permalink: /Experience/
title: "Projects"
author_profile: true
redirect_from: 
  - /md/
  - /markdown.html
---

**This page has not been completed yet**...

I'm trying, but life is hard sometimes...(e.g. playing splatoon!)

---



## Coarse Grained method for IF network and Spatially Ordered Network

**Advisor: Jiwei Zhang   School of Mathematics and Statistics, Wuhan University, China**

Integral-and-Fire(IF) neural network is a more biological neural network compared with the artificial neural network (ANN). It captures the key feature of neurons, namely spikes. However, it's really expansive to evolve this network because of the *curse of the dimensionality*. In ANN, the computation is quite fast, since the activation function is simple and the derivation is somehow trivial. In IF network however, we have to solve equation like this for each time step 

(the 2nd term in the right hand side repersents the total input, both from the background noise and other inputs from presynaptic neurons)

$$\frac{dV_i^Q}{dt} = -g_i(V_i^Q-V_L) + \sum_j\sum_k S^{QY}\delta(t - t_{jk}) $$

So is there any better method to solve the IF network? Well, yes! Take a simple all-to-all connected IF network for example. We do not care every neuron's voltage in each time step. Instead, we look for the probility distribution function(PDF) of voltage, or the mean firing rate $m(t)$ of the system. And the mean firing rate could be generated by the PDF. 

First, write down the master equation governing the evolution of PDF $\rho(v,t)$

$$\partial_t \rho^Q(v,t)=g_L\partial_v[(v-V_L)\rho^Q(v,t)]+\eta^Q[\rho^Q(v-S^{QY},t)-\rho^Q(v,t)]$$

To make it more clear, we transform this equation into the Fokker-Planck equation:

$$\partial_t \rho^Q(v,t)+g_L\partial_vJ^Q(\rho^Q(v,t))=0$$

Using boundary conditions, the firing rate $m^Q(t)$ could be written as:

$$m^Q(v,t)=g_LJ^Q(\rho^Q(v,t)) = -\frac{g_L\sigma^2}{2}\partial_v \rho^Q(V_T, t)$$

However, the get the firing rate $m(t)$, we have to solve the PDE, which is not easy. Thus, we try to transform the PDE into a sery of ODEs by introducing the moments:

$$M^Q_j(t)=\int^{V_T}_{-\infty}v^j\rho^Q(v,t)dv$$

Then, the higher order moment could be calculated via lower order moments:

$$\frac{dM^Q_j(t)}{dt}=-m^Q(t)V_T^j-jg_L[M^Q_j-\mu^QM^Q_{j-1}-\frac{j-1}{2}(\sigma^Q)^2M^Q_{j-2}]$$

However, to evolve such an ODEs system with given initial conditions $M(t_0),m(t_0)$, we need to compute $m(t)$ at each time step, which inquires computing $\rho(v,t)$. 

Instead of computing $\rho(v,t)$ directly (which needs solving PDE), we introduce the maximum entropy method by approximating the PDF $\rho(v,t)$ with the equilibruim solution $\rho_{eq}$

$$\rho_{eq}^Q=C\exp(-\frac{(v-\mu^Q)^2}{(\sigma^Q)^2})\int^{(V_T-\mu^Q)/\sigma^Q}_{(v-\mu^Q)/\sigma^Q}e^{s^2}ds$$

$$\rho_{me}(v)=\rho_{eq}(v)\exp(\sum_{j=0}^N\lambda_jv^j-1)$$

Above all, we could get the firing rate of a IF network by simply dealing with the ODEs system. This method is both fast and accurate. And with more moments introduced, the result becomes more accurate. 

<p><center><img src="http://qiuyoungwang.github.io/images/projects/Jiwei_1.png" alt="Jiwei_1" style="zoom: 50%" ></center></p>

I also built a spatially ordered IF network for further analysis.(The method discussed above is for all-to-all network. For spatial order, however, we need to do some modification.)



## More biological hippocampus model via cascade synapses

**Advisor: Stefano Fusi  Centre of Theoretical Neuroscience, Columbia University, U.S.** 

"Your past shapes your future". This most philosophical quote describes the importance of hippocampus. Yet many myteries reamains unsolved in this old, paleomammalian structure, place cells is one of the most attractive features for me.

Active when an animal enters a particular place in the environment, place cells play an important role in navigation. In this paper, Benna et al. suggests the place cells are not just memory cells, instead, they might be a natrual result of supervised learning if hippocampus could be considered as a sparse Auto-Encoder(AE). However, the place cells generated by AE model have weak history effects, which means a memory will fade away quickly. 

This contradiction may be caused by the synapse model in AE, which is simple and has no memory effect. Thus, we introduce the cascade synapse model in this paper(Benna Fusi 2016), which is designed to avoid the *catastrophic forgetting*.

<p><center><img src="http://qiuyoungwang.github.io/images/projects/Fusi_1.png" alt="Fusi_1" style="zoom: 50%" ></center></p>

 And we could see when the cascade model is introducd, the model has strong histroy effect.
<p><center><img src="http://qiuyoungwang.github.io/images/projects/Fusi_2.png" alt="Fusi_2" style="zoom: 50%" ></center></p>
<p><center><img src="http://qiuyoungwang.github.io/images/projects/Fusi_3.png" alt="Fusi_3" style="zoom: 50%" ></center></p>


## Molecular Interaction Network Model for STDP (Part of the Bachelor Degree Thesis)  

Spike Timing Dependent Plasticity (STDP) is believed to be a general rule in learning in brain. Basically, *neurons fire together, wire together*. The change of synaptic weight is related to the time interval between pre and post synaptic spikes. However, it remains to be unclear how neurons can generate such behavior. Since all the biological behavior could be thought as a combination of chemical reaction, here, we try to model this phenomenon from the point of molecular interaction. 

Most chemical reaction in orgnism is enzyme catalysis, thus we kinetic equation could be written in a rather simple form. For example:

$$V_0 = V_{max}\frac{[S]}{K_M + [S]}$$

An important signal pathway in STDP is CaMKII pathway, where $Ca^{2+}$ play a role as signal molecular. The whole interaction network is given below, and we use kinetic equations to get the concentration(or activity) or molecular in this reaction. As a result,  we could find there is 'bistable' in such a system. The strength of the inputs determined the whether the CaMKII is activated or not.



## Anti-bactrier materials

Well, this project is about chemistry and materials (which means 'cooking'). So I'll talk about them later...



